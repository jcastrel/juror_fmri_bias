#first drop rows with zero steps
data <- data[ which( data$TotalSteps != 0) , ]
pre_post_data <- merge(data,pre_steps,by=c('sub'))
#filter out extra rows related to fMRI
pre_post_data <- pre_post_data %>%
filter(trial_type =='rating')
#calculate percent change
##steps
pre_post_data$TotalSteps_pct_chng <- ((pre_post_data$TotalSteps - pre_post_data$meanTotalSteps_Pre)/(pre_post_data$meanTotalSteps_Pre))*100
##HR
pre_post_data$RestingHeartRate_pct_chng <- ((pre_post_data$RestingHeartRate - pre_post_data$meanHR_pre)/(pre_post_data$meanHR_pre))*100
pre_post_data <- pre_post_data %>%
filter(phase =='int')
ggplot(data, aes(x=TotalSteps)) + geom_histogram(color="black", fill='white') +
th + geom_vline(aes(xintercept=mean(TotalSteps)),
color="blue", linetype="dashed", size=1)
ggplot(pre_post_data, aes(x=TotalSteps_pct_chng)) + geom_histogram(color="black", fill='white') +
th + geom_vline(aes(xintercept=mean(TotalSteps_pct_chng)),
color="blue", linetype="dashed", size=1)
#drop outliers in steps change
#filter out extra rows related to fMRI
pre_post_data <- pre_post_data %>%
filter(abs(TotalSteps_pct_chng) < 101)
#dropped step change that doubled/halved
ggplot(pre_post_data, aes(x=TotalSteps_pct_chng)) + geom_histogram(color="black", fill='white') +
th + geom_vline(aes(xintercept=mean(TotalSteps_pct_chng)),
color="blue", linetype="dashed", size=1)
ggplot(data, aes(x=RestingHeartRate)) + geom_histogram(color="black", fill='white') +
th + geom_vline(aes(xintercept=mean(RestingHeartRate)),
color="blue", linetype="dashed", size=1)
ggplot(pre_post_data, aes(x=RestingHeartRate_pct_chng)) + geom_histogram(color="black", fill='white') + th + geom_vline(aes(xintercept=mean(RestingHeartRate_pct_chng)),
color="blue", linetype="dashed", size=1)
msg_type_norm <- lmer(TotalSteps_norm ~ s_ns*valence + ( 1| sub), data=pre_post_data)
summ(msg_type_norm)
msg_type <- lmer(TotalSteps_pct_chng ~ s_ns*valence + ( 1| sub), data=pre_post_data)
summ(msg_type)
interact_plot(msg_type, pred = 's_ns',modx = 'valence',
x.label = "Social/Non-Social",
main.title = " ",
legend.main="Valence",
y.label = "%Change in Total Daily Steps",
colors = cols) +
th
cat_plot(msg_type, pred = 's_ns',modx = 'valence',
x.label = "Social/Non-Social",
main.title = " ",
legend.main="Valence",
y.label = "%Change in Total Daily Steps",
colors = cols) +
th
cols <- c("#76c8ff","#0099ff","#005289")
cat_plot(msg_type, pred = 's_ns',modx = 'valence',
x.label = "Social/Non-Social",
main.title = " ",
legend.main="Valence",
y.label = "%Change in Total Daily Steps",
colors = cols) +
th
cat_plot(msg_type_norm, pred = 's_ns',modx = 'valence',
x.label = "Social/Non-Social",
main.title = " ",
legend.main="Valence",
y.label = "%Change in Total Daily Steps",
colors = cols) +
th
cat_plot(msg_type_norm, pred = 's_ns',modx = 'valence',
x.label = "Social/Non-Social",
main.title = " ",
legend.main="Valence",
y.label = "Total Daily Steps (Z)",
colors = cols) +
th
msg_type_raw <- lmer(TotalSteps_raw ~ s_ns*valence + ( 1| sub), data=pre_post_data)
summ(msg_type_raw)
msg_type_raw <- lmer(TotalSteps ~ s_ns*valence + ( 1| sub), data=pre_post_data)
summ(msg_type_raw)
cat_plot(msg_type_raw, pred = 's_ns',modx = 'valence',
x.label = "Social/Non-Social",
main.title = " ",
legend.main="Valence",
y.label = "Total Daily Steps",
colors = cols) +
th
plot(pre_post_data$subj_day_num,pre_post_data$TotalSteps_norm)
plot(pre_post_data$subj_day_num,pre_post_data$TotalSteps)
ggscatter(pre_post_data,x=subj_day_num,y=TotalSteps,point = FALSE,cor.coef = TRUE)
ggscatter(pre_post_data,x=subj_day_num,y=TotalSteps,point = FALSE,cor.coef = TRUE)
ggscatter(pre_post_data,x=subj_day_num,y=TotalSteps)
pre_post_data$subj_day_num
ggscatter(pre_post_data,x="subj_day_num",y="TotalSteps",point = FALSE,cor.coef = TRUE)
ggscatter(pre_post_data,x="subj_day_num",y="TotalSteps",cor.coef = TRUE)
ggscatter(pre_post_data,x="subj_day_num",y="TotalSteps",point = FALSE,cor.coef = TRUE, add = "reg.line")
ggscatter(pre_post_data,x="subj_day_num",y="TotalSteps",point = FALSE,cor.coef = TRUE, add = "reg.line", conf.int = TRUE)
ggscatter(pre_post_data,x="subj_day_num",y="TotalSteps_norm",point = FALSE,cor.coef = TRUE, add = "reg.line", conf.int = TRUE)
ggscatter(pre_post_data,x="subj_day_num",y="TotalSteps_pct_chng",point = FALSE,cor.coef = TRUE, add = "reg.line", conf.int = TRUE)
msg_rating <- lmer(TotalSteps_pct_chng ~ rating + ( 1| sub), data=pre_post_data)
summ(msg_rating)
msg_rating_norm <- lmer(TotalSteps_norm ~ rating + ( 1| sub), data=pre_post_data)
summ(msg_rating_norm)
msg_rating_raw <- lmer(TotalSteps ~ rating + ( 1| sub), data=pre_post_data)
summ(msg_rating_raw)
ggscatter(pre_post_data,x="rating",y="TotalSteps_pct_chng",point = FALSE,cor.coef = TRUE, add = "reg.line", conf.int = TRUE)
ggscatter(pre_post_data,x="rating",y="TotalSteps_norm",point = FALSE,cor.coef = TRUE, add = "reg.line", conf.int = TRUE)
ggscatter(pre_post_data,x="rating",y="TotalSteps",point = FALSE,cor.coef = TRUE, add = "reg.line", conf.int = TRUE)
ggscatter(pre_post_data,x="rating",y="TotalSteps",point = FALSE,cor.coef = TRUE, add = "reg.line", conf.int = TRUE)+ylim(0,15000)
ggscatter(pre_post_data,x="rating",y="TotalSteps",point = FALSE,cor.coef = TRUE, add = "reg.line", conf.int = TRUE)+ylim(5000,15000)
ggscatter(pre_post_data,x="rating",y="TotalSteps",point = FALSE,cor.coef = TRUE, add = "reg.line", conf.int = TRUE)+ylim(8000,12000)
library("rtweet")
get_token()
mn_tweets<-search_tweets(q = "minnesota", n = 2, lang = "en", include_rts = FALSE)
View(mn_tweets)
mn$text
mn_tweets$text
th_tweets<-search_tweets(q = "TomHolland1996", n = 2, lang = "en", include_rts = FALSE)
View(th_tweets)
th_follow<- get_followers(user = "TomHolland1996", n=4)
View(th_follow)
setwd("~/Desktop/juror_fmri_bias/fmri/roi_analysis")
#packages
library(dplyr)
library(lme4)
library(jtools)
library(ggplot2)
library(lmerTest)
library(magick)
library(gridBase)
library(sjPlot)
library(ggpubr)
#set seed (for reproducible effects)
set.seed(1000)
#theme
th <- theme_minimal() +
theme(plot.background = element_rect(fill = 'white', color = 'white'),
plot.title = element_text(face = 'bold', colour = 'black', size = 18),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.background = element_rect(fill = 'white',color = 'white'),
axis.line = element_line(colour = "black"),
axis.title.x = element_text(colour = "black", size = 16),
axis.title.y = element_text(colour = "black", size = 16),
axis.text=element_text(size = 16),
axis.text.x = element_text(colour = "black", size = 16),
axis.text.y = element_text(colour = "black", size = 16))
#open fmri parameter estimates data
data <- read.csv(file="./subject_scenario_mean_zstat.csv",
header=TRUE,
sep = ",",
na.strings=c("","NA"))
data <- within(data, {
victim_type <- factor(victim_type,
levels = 0:2,
labels = c('Victimless',
'Loss of Property',
'Injury or Loss of Life'))
subjectID <- factor(subjectID)
})
# grab behavior data
behavior <- read.csv(file="../../behavior/data/scenario_classification.csv",
header=TRUE,
sep = ",",
na.strings=c("","NA"))
behavior <- within(behavior, {
victim_type <- factor(JRL,
levels = 0:2,
labels = c('Victimless',
'Loss of Property',
'Injury or Loss of Life'))
category <- factor(category)
})
#grab pca data
pca <- read.csv(file="../../behavior/pca_loadings-fmri.csv",
header=TRUE,
sep = ",",
na.strings=c("","NA"))
pca <- within(pca, {
scenario <- factor(X)
})
#merge dataframes
behavior_data <- merge(behavior, pca, by='scenario')
#m0
m0_behavior <- lm(PC1 ~ 1, data = behavior_data)
summ(m0_behavior, scale = TRUE, confint = TRUE, digits = 4)
anova(m0_behavior)
#m1
m1_behavior <- lm(PC1 ~ factor(victim_type), data = behavior_data)
summ(m1_behavior, scale = TRUE, confint = TRUE, digits = 4)
anova(m1_behavior)
#m2
m2_behavior <- lm(PC1 ~ factor(category), data = behavior_data)
summ(m2_behavior, scale = TRUE, confint = TRUE, digits = 4)
anova(m2_behavior)
#m3
m3_behavior <- lm(PC1 ~ factor(victim_type) + factor(category), data = behavior_data)
summ(m3_behavior, scale = TRUE, confint = TRUE, digits = 4)
anova(m3_behavior)
#m4
m4_behavior <- lm(PC1 ~ factor(victim_type)*factor(category), data = behavior_data)
summ(m4_behavior, scale = TRUE, confint = TRUE, digits = 4)
anova(m4_behavior)
# MODEL COMPARISON/SELECTION #changed order of 1 & 2 to facilitate d.f. interpretation in output
behavior_crime_type_model_comparison <- anova(m0_behavior,m2_behavior,
m1_behavior,m3_behavior,
m4_behavior,test="Chisq")
behavior_crime_type_model_comparison
library(lmtest)
lmtest::lrtest(m0_behavior,m2_behavior,m1_behavior,m3_behavior,m4_behavior)
anova(m0_behavior,m2_behavior,
m1_behavior,m3_behavior,
m4_behavior,test="LRT")
setwd("~/Desktop/juror_fmri/behavior/docs")
knitr::opts_chunk$set(fig.pos= "H", out.extra='')
library(jsonlite)
sc <- fromJSON('../data/scenarios.json', flatten=TRUE)
template <- "### Scenario %s:
%s
- **Criminal History**
- *Related*:   %s
- *Unrelated*: %s
- *No prior*:  %s
- **Witness**
- *Witness*:   %s
- *No witness*: %s
- **Physical evidence**
- *DNA*:   %s
- *non-DNA*: %s
- *none*:  %s
"
sc_formatted <- sprintf(template, sc$abbr,
sc[['vars.base.Base']],
sc[['vars.Criminal History.relatedPrior']],
sc[['vars.Criminal History.unrelatedPrior']],
sc[['vars.Criminal History.noPrior']],
sc[['vars.Witness.isWitness']],
sc[['vars.Witness.noWitness']],
sc[['vars.Physical Evidence.DNA']],
sc[['vars.Physical Evidence.nonDNA']],
sc[['vars.Physical Evidence.noPhys']]
)
cat(sc_formatted, sep='')
install.packages('tinytex')
tinytex::install_tinytex()
install.packages('tinytex')
tinytex::install_tinytex()
capabilities()
setwd("~/Desktop/juror_fmri_bias/fmri/roi_analysis")
#packages
library(dplyr)
library(lme4)
library(jtools)
library(ggplot2)
library(lmerTest)
library(magick)
library(gridBase)
library(sjPlot)
library(ggpubr)
#set seed (for reproducible effects)
set.seed(1000)
#theme
th <- theme_minimal() +
theme(plot.background = element_rect(fill = 'white', color = 'white'),
plot.title = element_text(face = 'bold', colour = 'black', size = 18),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.background = element_rect(fill = 'white',color = 'white'),
axis.line = element_line(colour = "black"),
axis.title.x = element_text(colour = "black", size = 16),
axis.title.y = element_text(colour = "black", size = 16),
axis.text=element_text(size = 16),
axis.text.x = element_text(colour = "black", size = 16),
axis.text.y = element_text(colour = "black", size = 16))
#open fmri parameter estimates data
data <- read.csv(file="./subject_scenario_mean_zstat.csv",
header=TRUE,
sep = ",",
na.strings=c("","NA"))
data <- within(data, {
victim_type <- factor(victim_type,
levels = 0:2,
labels = c('Victimless',
'Loss of Property',
'Injury or Loss of Life'))
subjectID <- factor(subjectID)
})
# grab behavior data
behavior <- read.csv(file="../../behavior/data/scenario_classification.csv",
header=TRUE,
sep = ",",
na.strings=c("","NA"))
behavior <- within(behavior, {
victim_type <- factor(JRL,
levels = 0:2,
labels = c('Victimless',
'Loss of Property',
'Injury or Loss of Life'))
category <- factor(category)
})
#grab pca data
pca <- read.csv(file="../../behavior/pca_loadings-fmri.csv",
header=TRUE,
sep = ",",
na.strings=c("","NA"))
pca <- within(pca, {
scenario <- factor(X)
})
#merge dataframes
behavior_data <- merge(behavior, pca, by='scenario')
#m0
m0_behavior <- lm(PC1 ~ 1, data = behavior_data)
summ(m0_behavior, scale = TRUE, confint = TRUE, digits = 4)
anova(m0_behavior)
#m1
m1_behavior <- lm(PC1 ~ factor(victim_type), data = behavior_data)
summ(m1_behavior, scale = TRUE, confint = TRUE, digits = 4)
anova(m1_behavior)
#m2
m2_behavior <- lm(PC1 ~ factor(category), data = behavior_data)
summ(m2_behavior, scale = TRUE, confint = TRUE, digits = 4)
anova(m2_behavior)
#m3
m3_behavior <- lm(PC1 ~ factor(victim_type) + factor(category), data = behavior_data)
summ(m3_behavior, scale = TRUE, confint = TRUE, digits = 4)
anova(m3_behavior)
#m4
m4_behavior <- lm(PC1 ~ factor(victim_type)*factor(category), data = behavior_data)
summ(m4_behavior, scale = TRUE, confint = TRUE, digits = 4)
anova(m4_behavior)
lmtest::lrtest(m0_behavior,m2_behavior,m1_behavior,m3_behavior,m4_behavior)
export_summs(m0_behavior,m1_behavior,m2_behavior,m3_behavior,m4_behavior)
BIC(m0_behavior,m2_behavior,m1_behavior,m3_behavior,m4_behavior)
setwd("~/Desktop/juror_fmri_bias/behavior/text_analysis_scenario")
knitr::opts_chunk$set(echo = TRUE, dev = c('png','pdf'))
library(tidytext)
library(tidyr)
library(dplyr)
library(ggplot2)
library(ggcorrplot)
library(ggpubr)
library(wordcloud)
library(quanteda)
#robust correlation & regression
library(robcor)
library(MASS)
library(quantreg)
setwd("~/Desktop/juror_fmri_bias/behavior/text_analysis_scenario")
data <- read.csv(file="./scenario_classification.csv", header=TRUE, sep = ",", stringsAsFactors=FALSE)
data <- within(data, {
crime_type <- factor(crime_type)
category <- factor(category)
jrl <- factor(jrl)
class <- factor(class)
})
th <- theme_classic()
set.seed(1000)
crimes <- data %>%
mutate(index = scenario) %>%
ungroup()
tidy_crimes <- crimes %>%
unnest_tokens(word, crime_description, token = "words")
#quick word count
word_count <- tidy_crimes %>%
group_by(scenario) %>%
summarise(count = n())
sentiment_nrc <- tidy_crimes %>%
anti_join(stop_words) %>%
group_by(scenario) %>%
inner_join(get_sentiments("nrc"), by = "word") %>%
count(index = index, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative)
sentiment_nrc
sentiment_afinn <- tidy_crimes %>%
anti_join(stop_words) %>%
group_by(scenario) %>%
inner_join(get_sentiments("afinn"), by = "word") %>%
summarise(sentiment_score = sum(score))
sentiment_afinn <- tidy_crimes %>%
anti_join(stop_words) %>%
group_by(scenario) %>%
inner_join(get_sentiments("afinn"), by = "word")
sentiment_afinn
sentiment_afinn <- tidy_crimes %>%
anti_join(stop_words) %>%
group_by(scenario) %>%
inner_join(get_sentiments("afinn"), by = "word")
sentiment_afinn
sentiment_afinn <- tidy_crimes %>%
anti_join(stop_words) %>%
group_by(scenario) %>%
inner_join(get_sentiments("afinn"), by = "word") %>%
summarise(sentiment_score = sum(value))
sentiment_afinn
sentiment_afinn <- tidy_crimes %>%
anti_join(stop_words) %>%
group_by(scenario) %>%
inner_join(get_sentiments("afinn"), by = "word") %>%
summarise(sentiment_score = sum(value))
sentiment_afinn
ggplot(sentiment_afinn, aes(x=sentiment_score)) + geom_histogram(binwidth = 1, color="black", fill="lightblue") + geom_vline(aes(xintercept=mean(sentiment_score)), color="blue", linetype="dashed", size=1)+th
# word, sentence, and syllable counts, plus reading scores
read_lvl <- data %>%
mutate(syllables = nsyllable(crime_description),
sentences = nsentence(crime_description),
words = ntoken(crime_description, remove_punct = TRUE),
fk_grade = 0.39*(words/sentences) + 11.8*(syllables/words) - 15.59) %>%
arrange(scenario)
read_lvl <- dplyr::select(read_lvl,-c(2,3,4,5,6,7,8))
#sentiment & word count
all_data <- data %>%
#inner_join(sentiment, by = "scenario") %>%
inner_join(word_count, by = "scenario") %>%
inner_join(sentiment_nrc, by = "scenario") %>%
inner_join(read_lvl, by = "scenario")
afinn_data<-data %>%
inner_join(sentiment_afinn, by = 'scenario')
bing_data<-data %>%
inner_join(sentiment_bing, by = 'scenario')
sentiment_bing <- tidy_crimes %>%
anti_join(stop_words) %>%
group_by(scenario) %>%
inner_join(get_sentiments("bing"), by = "word") %>%
count(index = index, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative)
sentiment_bing
corr <- round(cor(all_data[7:25],method="spearman"), 3)
ggcorrplot(corr, hc.order = FALSE, type = "lower", outline.color = "white",
lab = TRUE)
corr <- round(cor(afinn_data[7:9],method="spearman"), 3)
ggcorrplot(corr, hc.order = FALSE, type = "lower", outline.color = "white",
lab = TRUE)
corr <- round(cor(bing_data[7:12],method="spearman"), 3)
afinn_data<-data %>%
inner_join(sentiment_afinn, by = 'scenario')
bing_data<-data %>%
inner_join(sentiment_bing, by = 'scenario')
corr <- round(cor(bing_data[7:12],method="spearman"), 3)
ggcorrplot(corr, hc.order = FALSE, type = "lower", outline.color = "white",
lab = TRUE)
#sentiment - case strength
ggscatter(all_data, x = "case_strength_mean", y = "sentiment",
color = "black", shape = 21, size = 3,
add = "reg.line",
add.params = list(color = "blue", fill = "lightgray"),
conf.int = TRUE,
cor.coef = TRUE,
cor.coeff.args = list(method = "spearman", label.x = 3, label.sep = "\n")
) + th
ggscatter(all_data, x = "case_strength_mean", y = "sentiment",
fill = "black", shape = 21, size = 3,
add = "reg.line",
add.params = list(color = "gray", fill = "lightgray"),
conf.int = TRUE,
cor.coef = TRUE,
cor.coeff.args = list(method = "spearman", label.x = 3, label.sep = "\n")
) + th
ggscatter(all_data, x = "case_strength_mean", y = "sentiment",
fill = "black", shape = 21, size = 3,
add = "reg.line",
add.params = list(color = "black", fill = "lightgray"),
conf.int = TRUE,
cor.coef = TRUE,
cor.coeff.args = list(method = "spearman", label.x = 3, label.sep = "\n")
) + th
ggscatter(all_data, x = "case_strength_mean", y = "sentiment",
fill = "black", shape = 21, size = 3,
add = "reg.line",
add.params = list(color = "black", fill = "lightgray"),
conf.int = TRUE,
cor.coef = TRUE,
cor.coeff.args = list(method = "spearman", label.x = 3, label.sep = "\n")
) + th +
xlab("Case Strength") + ylab("Sentiment")
ggscatter(all_data, x = "case_strength_mean", y = "words",
color = "black", shape = 21, size = 3,
add = "reg.line",
add.params = list(color = "blue", fill = "lightgray"),
conf.int = TRUE,
cor.coef = TRUE,
cor.coeff.args = list(method = "spearman", label.x = 3, label.sep = "\n")
)
ggscatter(all_data, x = "case_strength_mean", y = "words",
fill = "black", shape = 21, size = 3,
add = "reg.line",
add.params = list(color = "black", fill = "lightgray"),
conf.int = TRUE,
cor.coef = TRUE,
cor.coeff.args = list(method = "spearman", label.x = 3, label.sep = "\n")
)
ggscatter(all_data, x = "case_strength_mean", y = "words",
fill = "black", shape = 21, size = 3,
add = "reg.line",
add.params = list(color = "black", fill = "lightgray"),
conf.int = TRUE,
cor.coef = TRUE,
cor.coeff.args = list(method = "spearman", label.x = 3, label.sep = "\n")
) + xlab("Case Strength") + ylab ("Sum Scenario Text Word Count")
ggscatter(all_data, x = "punishment_mean", y = "words",
color = "black", shape = 21, size = 3, # Points color, shape and size
add = "reg.line",  # Add regressin line
add.params = list(color = "blue", fill = "lightgray"), # Customize reg. line
conf.int = TRUE, # Add confidence interval
cor.coef = TRUE, # Add correlation coefficient. see ?stat_cor
cor.coeff.args = list(method = "pearson", label.x = 3, label.sep = "\n")
) + xlab("Punishment") + ylab ("Sum Scenario Text Word Count")
ggscatter(all_data, x = "punishment_mean", y = "words",
fill = "black", shape = 21, size = 3, # Points color, shape and size
add = "reg.line",  # Add regressin line
add.params = list(color = "black", fill = "lightgray"), # Customize reg. line
conf.int = TRUE, # Add confidence interval
cor.coef = TRUE, # Add correlation coefficient. see ?stat_cor
cor.coeff.args = list(method = "pearson", label.x = 3, label.sep = "\n")
) + xlab("Punishment") + ylab ("Sum Scenario Text Word Count")
