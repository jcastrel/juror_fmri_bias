{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Juror fMRI Parameter Estimate Organization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paths\n",
    "files = glob.glob('data/*/*/*thresh*.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['19933', '19934', '19947', '19953', '19963', '19968', '19974', '19977', '19980', '19983', '19993', '20000', '20007', '20009', '20010', '20022', '20026', '20031', '20032', '20033', '20036', '20059', '20070', '20073', '20074', '20075', '20080', '20101', '20109']\n"
     ]
    }
   ],
   "source": [
    "#get subject ID - will use to match files\n",
    "subject_list = []\n",
    "event_list = []\n",
    "mask_list = []\n",
    "for filename in files:\n",
    "    splitdir = filename.split('/')\n",
    "    subjID = splitdir[1]\n",
    "    subject_list.append(subjID)\n",
    "subject_list = list(set(subject_list))\n",
    "subject_list.sort()\n",
    "print(subject_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenario Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## grab mean parameter estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#event & mask list\n",
    "event_list = ['scenario']\n",
    "mask_list = ['juror_scenario_thresh_mask']\n",
    "\n",
    "#read each dataframe\n",
    "df_mask = []\n",
    "for m in mask_list:\n",
    "    df_evs = []\n",
    "    for ev in event_list:\n",
    "        df_sub = []\n",
    "        avg = pd.DataFrame()\n",
    "        for sub in subject_list:\n",
    "            df = pd.read_csv(os.path.join('data/%s/%s/merged_%s_%s_%s.txt'%(sub,ev,sub,ev,m)),header=None,sep='\\t',names=['zstat'])\n",
    "            df['subjectID'] = sub\n",
    "            df['m'] = m\n",
    "            df['event'] = ev\n",
    "            df_sub.append(df)\n",
    "df2 = pd.concat(df_sub, ignore_index=True, axis=0)\n",
    "\n",
    "#add repeating rows for the case number\n",
    "from itertools import cycle\n",
    "seq = cycle(range(1,34))\n",
    "df2['scenario'] = [next(seq) for count in range(df2.shape[0])]\n",
    "\n",
    "#rearrange column order\n",
    "df2 = df2[['subjectID', 'm', 'event', 'scenario', 'zstat']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add extra scenario variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scenario classification info\n",
    "scenario_class = pd.read_csv('../../behavior/data/scenario_classification.csv')\n",
    "#subset data\n",
    "scenario_class = scenario_class[['scenario', 'category', 'JRL']]\n",
    "scenario_class = scenario_class.rename(columns={'Category': 'crime_severity', \"JRL\": 'victim_type'})\n",
    "\n",
    "#pca results\n",
    "scenario_pca_results = pd.read_csv('../../behavior/pca_loadings-fmri.csv')\n",
    "scenario_pca_results = scenario_pca_results.rename(columns={'Unnamed: 0': 'scenario'})\n",
    "\n",
    "merged_scenario_info = pd.merge_ordered(scenario_class, scenario_pca_results, on=\"scenario\")\n",
    "\n",
    "all_data = pd.merge_ordered(df2, merged_scenario_info, on=\"scenario\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.to_csv('subject_scenario_mean_zstat.csv', index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evidence Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## grab mean parameter estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#event & mask list\n",
    "event_list = ['evidence']\n",
    "mask_list = ['juror_evidence_thresh_mask']\n",
    "#mask_list = ['avg_reading_evidence_mask']\n",
    "\n",
    "#read each dataframe\n",
    "df_mask = []\n",
    "for m in mask_list:\n",
    "    df_evs = []\n",
    "    for ev in event_list:\n",
    "        df_sub = []\n",
    "        avg = pd.DataFrame()\n",
    "        for sub in subject_list:\n",
    "            df = pd.read_csv(os.path.join('data/%s/%s/merged_%s_%s_%s.txt'%(sub,ev,sub,ev,m)),header=None,sep='\\t',names=['zstat'])\n",
    "            df['subjectID'] = sub\n",
    "            df['m'] = m\n",
    "            df['event'] = ev\n",
    "            df_sub.append(df)\n",
    "df2 = pd.concat(df_sub, ignore_index=True, axis=0)\n",
    "\n",
    "#add repeating rows for the case number\n",
    "from itertools import cycle\n",
    "seq = cycle(range(1,34))\n",
    "df2['scenario'] = [next(seq) for count in range(df2.shape[0])]\n",
    "\n",
    "#rearrange column order\n",
    "df2 = df2[['subjectID', 'm', 'event', 'scenario', 'zstat']]\n",
    "\n",
    "df2['subjectID'] = df2['subjectID'].astype(str).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get the sum of the case strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subject-level fmri timing info \n",
    "subj_data = pd.read_csv('../../behavior/data/all_juror_fmri_behavior_long.csv', encoding = 'latin-1')\n",
    "subj_data = subj_data.sort_values(by=['uid','scenario'])\n",
    "#rename subject variable\n",
    "subj_data = subj_data.rename(columns={'uid': 'subjectID'})\n",
    "\n",
    "#drop repeated rows (each subject has a row for case strength & punishment ratings)\n",
    "subj_data = subj_data[subj_data.rating_type != 'rate_punishment']\n",
    "\n",
    "#only need a couple columns\n",
    "subj_data = subj_data[['subjectID','scenario','history','witness','physical']]\n",
    "\n",
    "#######################\n",
    "#case strength weights\n",
    "evidence_cs = pd.read_csv('../../behavior/data/evidence_effects_fmri_sample.csv')\n",
    "#drop punishment values (keep case strength)\n",
    "evidence_cs = evidence_cs[evidence_cs.outcome == 'rating']\n",
    "#create a list of our conditions\n",
    "conditions = [\n",
    "    (evidence_cs['evidence'] == 'physicalNon-DNA'),\n",
    "    (evidence_cs['evidence'] == 'physicalDNA'),\n",
    "    (evidence_cs['evidence'] == 'historyUnrelated'),\n",
    "    (evidence_cs['evidence'] == 'historyRelated'),\n",
    "    (evidence_cs['evidence'] == 'witnessYes Witness')\n",
    "    ]\n",
    "#create a list of the values we want to assign for each condition\n",
    "ev_type = ['physical', 'physical',\n",
    "          'history', 'history',\n",
    "          'witness']\n",
    "\n",
    "ev_level = ['nonDNA', 'DNA',\n",
    "          'unrelatedPrior', 'relatedPrior',\n",
    "          'isWitness']\n",
    "#create a new column and use np.select to assign values to it using our lists as arguments\n",
    "evidence_cs['type'] = np.select(conditions, ev_type)\n",
    "evidence_cs['level'] = np.select(conditions, ev_level)\n",
    "#keep only a couple columns\n",
    "evidence_cs = evidence_cs[['mean','type','level']]\n",
    "#add data for no evidence\n",
    "listOfSeries = [pd.Series([0, 'physical', 'noPhys'], index=evidence_cs.columns ) ,\n",
    "                pd.Series([0, 'history', 'noPrior'], index=evidence_cs.columns ) ,\n",
    "                pd.Series([0, 'witness', 'noWitness'], index=evidence_cs.columns ) ]\n",
    "evidence_cs = evidence_cs.append(listOfSeries , ignore_index=True)\n",
    "\n",
    "\n",
    "#split the dataframe\n",
    "evidence_physical =  evidence_cs[evidence_cs.type == 'physical']\n",
    "evidence_physical = evidence_physical[['mean','level']]\n",
    "evidence_history = evidence_cs[evidence_cs.type == 'history']\n",
    "evidence_history = evidence_history[['mean','level']]\n",
    "evidence_witness = evidence_cs[evidence_cs.type == 'witness']\n",
    "evidence_witness = evidence_witness[['mean','level']]\n",
    "\n",
    "#replace the condition with the mean case strength weight\n",
    "\n",
    "#witness\n",
    "w = evidence_witness.set_index('level')['mean']\n",
    "subj_data['witness_weight'] = subj_data['witness'].replace(w)\n",
    "#history\n",
    "h = evidence_history.set_index('level')['mean']\n",
    "subj_data['history_weight'] = subj_data['history'].replace(h)\n",
    "#physical\n",
    "p = evidence_physical.set_index('level')['mean']\n",
    "subj_data['physical_weight'] = subj_data['physical'].replace(p)\n",
    "#sum the weights\n",
    "subj_data['weight_sum'] = subj_data['witness_weight']+subj_data['history_weight']+subj_data['physical_weight']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get the evidence text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim = '../../behavior/data/scenarios.json'\n",
    "stim_json = open(stim)\n",
    "stim_json = json.load(stim_json)\n",
    "stim_data = pd.json_normalize(stim_json)\n",
    "\n",
    "#rename default columns/var names\n",
    "stim_data = stim_data.rename(columns={'abbr': 'scenario',\n",
    "                                      'vars.base.Base':'base',\n",
    "                                      'vars.Criminal History.relatedPrior': 'history_relatedPrior',\n",
    "                                      'vars.Criminal History.unrelatedPrior':'history_unrelatedPrior',\n",
    "                                      'vars.Criminal History.noPrior':'history_noPrior',\n",
    "                                      'vars.Witness.isWitness':'witness_isWitness',\n",
    "                                      'vars.Witness.noWitness':'witness_noWitness',\n",
    "                                      'vars.Physical Evidence.DNA':'physical_DNA',\n",
    "                                      'vars.Physical Evidence.nonDNA':'physical_nonDNA',\n",
    "                                      'vars.Physical Evidence.noPhys':'physical_noPhys'})\n",
    "#format scenario number\n",
    "stim_data['scenario'] = stim_data['scenario'].astype(int)\n",
    "\n",
    "#melt dataframe\n",
    "stim_data = pd.melt(stim_data, id_vars=['scenario'],\n",
    "                    value_vars=['base', 'history_relatedPrior','history_unrelatedPrior','history_noPrior',\n",
    "                                'witness_isWitness','witness_noWitness','physical_DNA',\n",
    "                                'physical_nonDNA','physical_noPhys'],value_name='text',var_name='evidence')\n",
    "stim_data = stim_data.sort_values(by=['scenario','evidence'])\n",
    "\n",
    "#we're not really interested in the base text for now so let's get rid of it\n",
    "stim_data = stim_data[stim_data.evidence != 'base']\n",
    "\n",
    "#make an extra column to refine evidence types\n",
    "stim_data['level']=stim_data.evidence.str.split(\"_\").str[1]\n",
    "stim_data['type']=stim_data.evidence.str.split(\"_\").str[0]\n",
    "\n",
    "\n",
    "#count number of words (very simple)\n",
    "stim_data['word_count'] = stim_data.text.apply(lambda x: len(str(x).split(' ')))\n",
    "\n",
    "#merged_stim_info = pd.merge_ordered(stim_data, evidence_cs, on=['type','level'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Grade Level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rpy2.ipython extension is already loaded. To reload it, use:\n",
      "  %reload_ext rpy2.ipython\n"
     ]
    }
   ],
   "source": [
    "# enables the %%R magic, not necessary if you've already done this\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "library(dplyr)\n",
    "library(tidytext)\n",
    "library(quanteda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i stim_data -o read_lvl\n",
    "# word, sentence, and syllable counts, plus reading scores\n",
    "read_lvl <- stim_data %>%\n",
    "  mutate(syllables = nsyllable(text),\n",
    "         sentences = nsentence(text),\n",
    "         words = ntoken(text, remove_punct = TRUE),\n",
    "         fk_grade = 0.39*(words/sentences) + 11.8*(syllables/words) - 15.59) %>%\n",
    "  arrange(scenario)\n",
    "\n",
    "#read_lvl <- dplyr::select(read_lvl,-c(2,3,4,5,6,7,8)) #3=text,#4=level,#5=type,#6=wc,#7=syllab,#8=sentences,#9=words,#10=fk_grade\n",
    "read_lvl <- dplyr::select(read_lvl,-c(3,6,7,8,9))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back to Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scenario</th>\n",
       "      <th>evidence</th>\n",
       "      <th>text</th>\n",
       "      <th>level</th>\n",
       "      <th>type</th>\n",
       "      <th>word_count</th>\n",
       "      <th>fk_grade</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>history_noPrior</td>\n",
       "      <td>McNeil has no criminal record.</td>\n",
       "      <td>noPrior</td>\n",
       "      <td>history</td>\n",
       "      <td>5</td>\n",
       "      <td>5.240000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>history_noPrior</td>\n",
       "      <td>Archer has no criminal record.</td>\n",
       "      <td>noPrior</td>\n",
       "      <td>history</td>\n",
       "      <td>5</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>history_noPrior</td>\n",
       "      <td>Montes has no criminal record.</td>\n",
       "      <td>noPrior</td>\n",
       "      <td>history</td>\n",
       "      <td>5</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>history_noPrior</td>\n",
       "      <td>Galloway has no criminal record.</td>\n",
       "      <td>noPrior</td>\n",
       "      <td>history</td>\n",
       "      <td>5</td>\n",
       "      <td>9.960000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>history_noPrior</td>\n",
       "      <td>Fray has no criminal record.</td>\n",
       "      <td>noPrior</td>\n",
       "      <td>history</td>\n",
       "      <td>5</td>\n",
       "      <td>5.240000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>29</td>\n",
       "      <td>witness_noWitness</td>\n",
       "      <td>The driver of the van, dazed by the impact, wa...</td>\n",
       "      <td>noWitness</td>\n",
       "      <td>witness</td>\n",
       "      <td>16</td>\n",
       "      <td>9.825000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>30</td>\n",
       "      <td>witness_noWitness</td>\n",
       "      <td>Investigators were unable to find anyone who c...</td>\n",
       "      <td>noWitness</td>\n",
       "      <td>witness</td>\n",
       "      <td>13</td>\n",
       "      <td>12.172308</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>31</td>\n",
       "      <td>witness_noWitness</td>\n",
       "      <td>The boy is too traumatized to testify and ther...</td>\n",
       "      <td>noWitness</td>\n",
       "      <td>witness</td>\n",
       "      <td>12</td>\n",
       "      <td>9.740000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>32</td>\n",
       "      <td>witness_noWitness</td>\n",
       "      <td>No witnesses were present in the courthouse al...</td>\n",
       "      <td>noWitness</td>\n",
       "      <td>witness</td>\n",
       "      <td>12</td>\n",
       "      <td>13.673333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>33</td>\n",
       "      <td>witness_noWitness</td>\n",
       "      <td>No witness saw Harris either texting or driving.</td>\n",
       "      <td>noWitness</td>\n",
       "      <td>witness</td>\n",
       "      <td>8</td>\n",
       "      <td>6.705000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>264 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     scenario           evidence  \\\n",
       "0           1    history_noPrior   \n",
       "1           2    history_noPrior   \n",
       "2           3    history_noPrior   \n",
       "3           4    history_noPrior   \n",
       "4           5    history_noPrior   \n",
       "..        ...                ...   \n",
       "259        29  witness_noWitness   \n",
       "260        30  witness_noWitness   \n",
       "261        31  witness_noWitness   \n",
       "262        32  witness_noWitness   \n",
       "263        33  witness_noWitness   \n",
       "\n",
       "                                                  text      level     type  \\\n",
       "0                       McNeil has no criminal record.    noPrior  history   \n",
       "1                       Archer has no criminal record.    noPrior  history   \n",
       "2                       Montes has no criminal record.    noPrior  history   \n",
       "3                     Galloway has no criminal record.    noPrior  history   \n",
       "4                         Fray has no criminal record.    noPrior  history   \n",
       "..                                                 ...        ...      ...   \n",
       "259  The driver of the van, dazed by the impact, wa...  noWitness  witness   \n",
       "260  Investigators were unable to find anyone who c...  noWitness  witness   \n",
       "261  The boy is too traumatized to testify and ther...  noWitness  witness   \n",
       "262  No witnesses were present in the courthouse al...  noWitness  witness   \n",
       "263   No witness saw Harris either texting or driving.  noWitness  witness   \n",
       "\n",
       "     word_count   fk_grade  mean  \n",
       "0             5   5.240000   0.0  \n",
       "1             5   7.600000   0.0  \n",
       "2             5   7.600000   0.0  \n",
       "3             5   9.960000   0.0  \n",
       "4             5   5.240000   0.0  \n",
       "..          ...        ...   ...  \n",
       "259          16   9.825000   0.0  \n",
       "260          13  12.172308   0.0  \n",
       "261          12   9.740000   0.0  \n",
       "262          12  13.673333   0.0  \n",
       "263           8   6.705000   0.0  \n",
       "\n",
       "[264 rows x 8 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#merge the reading level with other stim info\n",
    "merged_stim_info_tmp = pd.merge_ordered(stim_data, read_lvl, on=['scenario','evidence','type','level'])\n",
    "\n",
    "merged_stim_info = pd.merge_ordered(merged_stim_info_tmp, evidence_cs, on=['type','level'])\n",
    "merged_stim_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the dataframe\n",
    "stim_physical = merged_stim_info[merged_stim_info.type == 'physical']\n",
    "stim_physical = stim_physical[['scenario','fk_grade','word_count','level']]\n",
    "stim_physical = stim_physical.rename(columns={'level': 'physical'})\n",
    "\n",
    "stim_history = merged_stim_info[merged_stim_info.type == 'history']\n",
    "stim_history = stim_history[['scenario','fk_grade','word_count','level']]\n",
    "stim_history = stim_history.rename(columns={'level': 'history'})\n",
    "\n",
    "stim_witness = merged_stim_info[merged_stim_info.type == 'witness']\n",
    "stim_witness = stim_witness[['scenario','fk_grade','word_count','level']]\n",
    "stim_witness = stim_witness.rename(columns={'level': 'witness'})\n",
    "\n",
    "\n",
    "merged_stim_info2 = subj_data.merge(stim_witness, how = 'inner', on = ['scenario', 'witness'])\n",
    "merged_stim_info2 = merged_stim_info2.rename(columns={'word_count': 'witness_wc','fk_grade': 'witness_fk_grade'})\n",
    "\n",
    "merged_stim_info2 = merged_stim_info2.merge(stim_history, how = 'inner', on = ['scenario', 'history'])\n",
    "merged_stim_info2 = merged_stim_info2.rename(columns={'word_count': 'history_wc','fk_grade': 'history_fk_grade'})\n",
    "\n",
    "merged_stim_info2 = merged_stim_info2.merge(stim_physical, how = 'inner', on = ['scenario', 'physical'])\n",
    "merged_stim_info2 = merged_stim_info2.rename(columns={'word_count': 'physical_wc','fk_grade': 'physical_fk_grade'})\n",
    "merged_stim_info2['wc_sum'] = merged_stim_info2['witness_wc']+merged_stim_info2['history_wc']+merged_stim_info2['physical_wc']\n",
    "merged_stim_info2['fk_grade_sum'] = merged_stim_info2['witness_fk_grade']+merged_stim_info2['history_fk_grade']+merged_stim_info2['physical_fk_grade']\n",
    "merged_stim_info2['fk_grade_avg'] = merged_stim_info2[['witness_fk_grade', 'history_fk_grade', 'physical_fk_grade']].mean(axis=1)\n",
    "\n",
    "\n",
    "all_data = pd.merge_ordered(df2, merged_stim_info2, on=['subjectID','scenario'])\n",
    "all_data.to_csv('subject_evidence_mean_zstat.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
